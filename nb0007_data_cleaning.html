<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>nb0007_data_cleaning.utf8</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/simplex.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<!-- Google Tag Manager -->

<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-NFJ7QKG');</script>

<!-- End Google Tag Manager -->

<!-- Script hiding navbar when scrolling down -->

<script>
  var didScroll;
  var lastScrollTop = 0;
  var delta = 1;
  var navbarHeight = $('[role="navigation"]').outerHeight();

  $(window).scroll(function(event) {
    didScroll = true;
  });

  setInterval(function() {
    if (didScroll) {
      hasScrolled();
      didScroll = false;
    }
  }, 250);

  function hasScrolled() {
    var st = $(this).scrollTop();

    if (Math.abs(lastScrollTop - st) <= delta)
      return;

    if (st > lastScrollTop && st > navbarHeight) {
      // Scroll Down
      $('[role="navigation"]').addClass('navbar-scroll-down');
    } else {
      // Scroll Up
      if (st + $(window).height() < $(document).height()) {
        $('[role="navigation"]').removeClass('navbar-scroll-down');
      }
    }

    lastScrollTop = st;
  }
</script>

<!-- End of script hiding navbar when scrolling down -->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<!-- Google Tag Manager (noscript) -->

<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NFJ7QKG"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

<!-- End Google Tag Manager (noscript) -->

<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header active">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="https://sauder.ubc.ca" target="_blank"><svg width="190" height="42.5" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 190 42.5" enable-background="new 0 0 190 42.5" xml:space="preserve">
  <path class="logo__primary" d="M93.7 24.8c-2.3 0-4.6-.5-6.7-1.5l.7-4c1.9 1 3.9 1.7 6.1 1.8 1.3 0 2.4-.6 2.4-1.7s-.6-1.7-3.2-2.6c-3.8-1.5-5.6-2.7-5.6-6 0-3.6 2.9-5.6 6.5-5.6 2-.1 4 .4 5.7 1.2l-.7 4c-1.5-1-3.3-1.5-5.1-1.5-1.5 0-2.1.6-2.1 1.5s.6 1.6 2.8 2.4c4.2 1.5 5.8 2.9 5.8 6.1.2 4.1-2.8 6-6.6 5.9zM115.5 24.8l-1.3-4.2h-6.7l-1.3 3.9h-4.6l6.8-19.3h5.3l6.6 18.6-4.8 1zM110.7 10l-2.2 6.9h4.5l-2.3-6.9zM129.2 24.9c-4.7 0-8-2.6-8-7.9V5.4h4.8V17c0 2.5 1.1 3.9 3.3 3.9 2.1 0 3.3-1.5 3.3-3.8V5.4h4.8V17c-.1 5.3-3.5 8-8.2 7.9zM147.3 24.6h-6.7V5.4h6.6c6.6 0 10.2 3.8 10.2 9.6s-3.6 9.6-10.1 9.6zm-.2-15.5h-1.7v11.8h1.7c3.4 0 5.5-1.8 5.5-5.8s-2.2-6-5.5-6zM160 24.6V5.4h11.9v3.8h-7.3v3.4h5.6l.6 4h-6.2v4.2h7.5v3.8H160zM190 24l-4.8.8-4.2-6.7h-1.5v6.6h-4.8V5.4h6.7c4.6 0 7.4 2.1 7.4 6.1.1 2.4-1.3 4.7-3.6 5.5l4.8 7zm-8.9-15h-1.6v5.6h1.5c2 0 3.3-1 3.3-2.8S183.2 9 181.1 9zM8 24.9c-4.7 0-8-2.6-8-7.9V5.5h4.9v11.6C4.9 19.5 6 21 8.1 21s3.3-1.5 3.3-3.8V5.5h4.8v11.6c-.1 5.3-3.5 7.8-8.2 7.8zM25.5 24.7h-6.4V5.5h6.5c4.4 0 6.5 1.9 6.5 4.9 0 1.8-1.1 3.4-2.8 4 2.1.5 3.6 2.5 3.4 4.7.2 3.7-2.6 5.6-7.2 5.6zm-.2-15.8h-1.7v4.4h1.6c1.8 0 2.7-.9 2.7-2.2s-.7-2.2-2.6-2.2zm0 7.4h-1.7v4.9h1.8c1.9 0 3-.8 3-2.5s-1.1-2.4-3.1-2.4zM44.1 25c-5.8 0-9.3-3.9-9.3-9.9s3.7-10 9.2-10c1.8-.1 3.7.4 5.3 1.2l-.7 4.3c-1.2-1-2.7-1.5-4.3-1.6-2.9 0-4.8 2.2-4.8 6s2.1 6 5.1 6c1.6-.1 3.1-.6 4.4-1.4l.6 3.9c-1.8 1-3.6 1.5-5.5 1.5zM27.9 42.3c-1 0-1.9-.2-2.8-.6l.2-1.2c.8.4 1.7.7 2.6.7s1.6-.5 1.6-1.1-.5-.9-1.6-1.3c-1.7-.5-2.6-1.1-2.6-2.3.1-1.4 1.2-2.4 2.6-2.4h.1c.8 0 1.6.2 2.4.5l-.3 1.4c-.7-.3-1.4-.5-2.1-.6-.8 0-1.3.5-1.3.9 0 .7.5.8 1.7 1.2 1.7.5 2.5 1.1 2.5 2.3-.1 1.7-1.3 2.6-3 2.5zM36.8 42.5c-2.4 0-3.8-1.7-3.8-4.2s1.6-4.2 3.8-4.2c.8 0 1.6.2 2.4.6l-.3 1.3c-.6-.4-1.3-.7-2-.7-1.6 0-2.5 1.1-2.5 2.9s.9 2.9 2.5 2.9c.8 0 1.5-.3 2.1-.8l.2 1.2c-.7.7-1.5.9-2.4 1zM46.9 42.2v-3.5h-3.7v3.5h-1.5v-8h1.5v3.2h3.7v-3.1h1.5v8l-1.5-.1zM54.8 42.5c-2.1 0-3.9-1.8-3.8-3.9v-.2c-.2-2.1 1.4-3.9 3.5-4.1 2.1-.2 3.9 1.4 4.1 3.5v.6c.2 2.1-1.5 4-3.6 4.2 0-.1-.1-.1-.2-.1zm0-7.2c-1.6 0-2.4 1.2-2.4 2.9s.9 2.9 2.4 2.9 2.4-1.3 2.4-2.9-.9-2.9-2.4-2.9zM64.7 42.5c-2.1 0-3.9-1.8-3.8-3.9v-.2c-.2-2.1 1.4-3.9 3.5-4.1 2.1-.2 3.9 1.4 4.1 3.5v.6c.2 2.1-1.5 4-3.6 4.2 0-.1-.1-.1-.2-.1zm0-7.2c-1.6 0-2.4 1.2-2.4 2.9s.9 2.9 2.4 2.9 2.4-1.3 2.4-2.9-.9-2.9-2.4-2.9zM71.1 42.2v-8h1.5V41h3l.2 1.2h-4.7zM86.1 42.5c-2.1 0-3.9-1.8-3.8-3.9v-.2c-.2-2.1 1.4-3.9 3.5-4.1s3.9 1.4 4.1 3.5v.6c.2 2.1-1.5 4-3.6 4.2-.1-.1-.1-.1-.2-.1zm0-7.2c-1.6 0-2.4 1.2-2.4 2.9s.9 2.9 2.4 2.9 2.4-1.3 2.4-2.9-.9-2.9-2.4-2.9zM94 35.5v2.2h2.7l.2 1.2H94v3.4h-1.5v-8h4.8v1.2H94zM106.8 42.2h-2.6v-8h2.6c1.8 0 2.7.8 2.7 2 .1.8-.4 1.5-1.1 1.7.9.1 1.6 1 1.6 1.9-.2 1.7-1.4 2.4-3.2 2.4zm-.1-6.7h-1.1v2h1.1c1 0 1.5-.3 1.5-1.1 0-.6-.5-.9-1.5-.9zm.1 3.2h-1.2v2.5h1.2c1 0 1.7-.3 1.7-1.2s-.6-1.3-1.7-1.3zM115.6 42.5c-1.7.2-3.1-1.1-3.3-2.7v-5.5h1.4v4.8c0 1.3.6 2.1 1.8 2.1s1.9-.8 1.9-2.1v-4.8h1.5v4.8c.1 1.7-1.1 3.2-2.9 3.4h-.4zM124.2 42.3c-1 0-1.9-.2-2.8-.6l.2-1.2c.8.4 1.7.7 2.6.7s1.6-.5 1.6-1.1-.4-.9-1.6-1.3c-1.7-.6-2.6-1.1-2.6-2.4.1-1.4 1.2-2.4 2.6-2.4h.1c.8 0 1.6.2 2.4.5l-.2 1.3c-.7-.3-1.4-.5-2.1-.6-.8 0-1.3.5-1.3.9 0 .7.4.8 1.7 1.2 1.7.6 2.5 1.1 2.5 2.4-.2 1.8-1.3 2.6-3.1 2.6zM129.8 42.2v-8h1.5v8h-1.5zM139.7 42.2l-4-6v6h-1.4v-8h1.5l3.8 5.7v-5.7h1.4v8h-1.3zM143.9 42.2v-8h4.9v1.2h-3.6v2h2.8l.2 1.2h-3V41h3.7v1.2h-5zM153.7 42.3c-1 0-1.9-.2-2.8-.6l.2-1.2c.8.4 1.7.7 2.6.7.9 0 1.6-.5 1.6-1.1s-.4-.9-1.6-1.3c-1.7-.6-2.6-1.1-2.6-2.4.1-1.4 1.2-2.4 2.6-2.4h.1c.8 0 1.6.2 2.4.5l-.2 1.3c-.7-.3-1.4-.5-2.1-.6-.8 0-1.4.5-1.4.9 0 .7.4.8 1.7 1.2 1.7.6 2.5 1.1 2.5 2.4 0 1.8-1.2 2.6-3 2.6zM161.5 42.3c-1 0-1.9-.2-2.8-.6l.2-1.2c.8.4 1.7.7 2.6.7.9 0 1.6-.5 1.6-1.1s-.4-.9-1.6-1.3c-1.7-.6-2.6-1.1-2.6-2.4.1-1.4 1.2-2.4 2.6-2.4h.1c.8 0 1.6.2 2.4.5l-.2 1.3c-.7-.3-1.4-.5-2.1-.6-.8 0-1.4.5-1.4.9 0 .7.4.8 1.7 1.2 1.7.6 2.5 1.1 2.5 2.4-.1 1.8-1.2 2.6-3 2.6zM68.3 19.9l-6 4.6V5.7l6 5.2v9z"></path>
  <path class="logo__secondary" d="M75.3 25.2l4.6 3.6V.8l-4.6 4v20.4zM61.6 25.2l-4.7 3.6V.8l4.7 4v20.4zM74.7 4.4L79.8 0H57l5 4.4h12.7z"></path>
</svg></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="active">
  <a href="index.html">Analytics@Sauder</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="https://blogs.ubc.ca/businessanalytics">News</a>
</li>
<li>
  <a href="notebooks.html">Notebooks</a>
</li>
<li>
  <a href="resources.html">Resources</a>
</li>
<li class="cta">
  <a href="contribute.html" style="
    color: #ffffff;
">Get Involved</a>
</li>

      </ul>
      <ul class="nav navbar-nav navbar-right">

      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<div id="data-cleaning" class="section level2">
<h2>Data Cleaning</h2>
<div id="author-hao-zheng" class="section level4">
<h4>Author: Hao Zheng</h4>
<p>It is always amazing to see how insights can be generated by data scientists. However, in real life, not all collected data sets can be directly analyzed with existing tools, primarily due to the chaotic nature of data. Data scientists spend 80% of their time in simply cleaning up the data. Therefore, it is important to understand how to manage messy data in order to transform them into organized data that are ready for further processing.</p>
<p>In this Project, we will be introducing eight basic techniques that can be applied to most of the data sets that you will encounter. Our goal is to transform extremely messy data into less messy data. It is likely that, after applying these techniques, your data set will still not completely ready for further processing. This is because each data set has its unique problems, and you find yourself needing to adjust the application of these data cleaning techniques based on your data set’s problems. However, having these techniques in your back pocket will certainly be an asset as you prepare and clean your data.</p>
<p>We encourage you to create your own Jupytor notebook and follow along. You can also download this notebook together with any affiliated data in the <a href="https://github.com/Master-of-Business-Analytics/Notebooks_and_Data">Notebooks and Data</a> GitHub repository. Alternatively, if you do not have Python or Jupyter Notebook installed yet, you may experiment with a virtual notebook by launching Binder or Syzygy below (learn more about these two tools in the <a href="https://analytics-at-sauder.github.io/resource.html">Resource</a> tab).</p>
<p><a href="https://ubc.syzygy.ca/jupyter/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2FAnalytics-at-Sauder%2FNB0007_Data_Cleaning&urlpath=tree%2FNB0007_Data_Cleaning%2Fnb0007_data_cleaning.ipynb&branch=master" target="_blank" class="button">Launch Syzygy (UBC)</a></p>
<p><a href="https://pims.syzygy.ca/jupyter/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2FAnalytics-at-Sauder%2FNB0007_Data_Cleaning&urlpath=tree%2FNB0007_Data_Cleaning%2Fnb0007_data_cleaning.ipynb&branch=master" target="_blank" class="button">Launch Syzygy (Google)</a></p>
<p><a href="https://mybinder.org/v2/gh/Analytics-at-Sauder/NB0007_Data_Cleaning/master?filepath=nb0007_data_cleaning.ipynb" target="_blank" class="button">Launch Binder</a></p>
</div>
</div>
<div id="business-problem" class="section level1">
<h1>Business Problem</h1>
<p>Why do we need to clean the data before applying our desired statistical analyses, when we are really interested in generating business insights? In order to answer this question, we need to understand that there is a gap between raw data and the insights that business managers are interested in. Let’s use the retail industry as an example. Questions that are usually asked in the retail industry include: * Q1: Which geographic location provides us with the most profit per person? * Q2: What type of customers generate the most revenue for us?</p>
<p>However, the raw data set can only record the transactions from customers enrolled in the business’ loyalty program. In the process of recording these transactions, we may miss some of the information that is required to solve the aforementioned problems, such as: * The recorded transaction only included the name of the store, but you do not know where some of these stores are located. * The customers were not willing to share certain personal information due to privacy concerns.</p>
<p>In such scenarios, if we attempted to directly apply our statistical methods to this raw data set, we would likely have peculiar results on our hands: * Q1: The stores in Happyland (perhaps a community with only 1,000 residents) provides us with the most profit per person. * Q2: The customers who were not willing to share their gender identity generate the most revenue for us.</p>
<p>The above two insights are only “correct” in a statistical sense. In a business context, they provide little to no value. For example, it would not make sense for us to open up more stores in the small, but profitable, community of Happyland, and knowing that those customers who care about their privacy are the ones who generate the most revenue for us does not provide a good indication of who they truly are. Therefore, we use the data cleaning process to help close the gap between the messy, raw data set and the insights desired by business managers.</p>
<p>Let’s walk through the data cleaning process using an ongoing example for the remainder of the Project. Here, we have a data set that captures the constuction developments that occur around different neighbourhoods. Can we determine which neighbourhood has the most “constr type 3” construction projects?</p>
<div id="data-set-check" class="section level2">
<h2>Data Set Check</h2>
<pre class="python"><code>import pandas as pd
import numpy as np
import warnings

# This step prevent warning from showing up for formatting purpose,but ignore this line while practicing yourself
warnings.filterwarnings(&quot;ignore&quot;)

mydata = pd.read_csv(&quot;nb0007_data/Building_Permits.csv&quot;)</code></pre>
<pre class="python"><code>mydata.head(1)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Permit Number
</th>
<th>
Permit Type
</th>
<th>
Permit Type Definition
</th>
<th>
Permit Creation Date
</th>
<th>
Block
</th>
<th>
Lot
</th>
<th>
Street Number
</th>
<th>
Street Number Suffix
</th>
<th>
Street Name
</th>
<th>
Street Suffix
</th>
<th>
…
</th>
<th>
Existing Construction Type
</th>
<th>
Existing Construction Type Description
</th>
<th>
Proposed Construction Type
</th>
<th>
Proposed Construction Type Description
</th>
<th>
Site Permit
</th>
<th>
Supervisor District
</th>
<th>
Neighborhoods - Analysis Boundaries
</th>
<th>
Zipcode
</th>
<th>
Location
</th>
<th>
Record ID
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
201505065519
</td>
<td>
4
</td>
<td>
sign - erect
</td>
<td>
05/06/2015
</td>
<td>
0326
</td>
<td>
023
</td>
<td>
140
</td>
<td>
NaN
</td>
<td>
Ellis
</td>
<td>
St
</td>
<td>
…
</td>
<td>
3.0
</td>
<td>
constr type 3
</td>
<td>
NaN
</td>
<td>
NaN
</td>
<td>
NaN
</td>
<td>
3.0
</td>
<td>
Tenderloin
</td>
<td>
94102.0
</td>
<td>
(37.785719256680785, -122.40852313194863)
</td>
<td>
1380611233945
</td>
</tr>
</tbody>
</table>
<p>
1 rows × 43 columns
</p>
</div>
<p>Before moving into data cleaning, we need to understand what is happening in the dataset so that we can know in which way the data set is “sick:. It is obvious that there are lots of NaN values existing in the dataset. We definitely don’t want NA values here otherwise we will be having”security concerning customer" issue. That extra space and and NA value would be what we want to look at first.</p>
<p>Here, we have our first glimpse of the data. Before moving into the data cleaning process, it is crucial to grasp what is happening in the data set in order to understand the ways in which our data set is problematic and thus needs to be cleaned. It is obvious that there are several “NaN” values existing in the data set above. We definitely do not want to have NA values in our data set, or else we may run into analytical issues later on when we try and generate business insights from this data set. Let’s start by tackling the extra spaces (Step 1) and the NA values (Step 2) in our example data set.</p>
<pre class="python"><code># get info about all columns
mydata.info()

# create some exploratory visualization
mydata.isna().sum().plot(kind=&#39;bar&#39;)</code></pre>
<p>&lt;class ‘pandas.core.frame.DataFrame’&gt; RangeIndex: 198900 entries, 0 to 198899 Data columns (total 43 columns): # Column Non-Null Count Dtype<br />
— —— ————– —–<br />
0 Permit Number 198900 non-null object 1 Permit Type 198900 non-null int64<br />
2 Permit Type Definition 198900 non-null object 3 Permit Creation Date 198900 non-null object 4 Block 198900 non-null object 5 Lot 198900 non-null object 6 Street Number 198900 non-null int64<br />
7 Street Number Suffix 2216 non-null object 8 Street Name 198900 non-null object 9 Street Suffix 196132 non-null object 10 Unit 29479 non-null float64 11 Unit Suffix 1961 non-null object 12 Description 198610 non-null object 13 Current Status 198900 non-null object 14 Current Status Date 198900 non-null object 15 Filed Date 198900 non-null object 16 Issued Date 183960 non-null object 17 Completed Date 97191 non-null object 18 First Construction Document Date 183954 non-null object 19 Structural Notification 6922 non-null object 20 Number of Existing Stories 156116 non-null float64 21 Number of Proposed Stories 156032 non-null float64 22 Voluntary Soft-Story Retrofit 35 non-null object 23 Fire Only Permit 18827 non-null object 24 Permit Expiration Date 147020 non-null object 25 Estimated Cost 160834 non-null float64 26 Revised Cost 192834 non-null float64 27 Existing Use 157786 non-null object 28 Existing Units 147362 non-null float64 29 Proposed Use 156461 non-null object 30 Proposed Units 147989 non-null float64 31 Plansets 161591 non-null float64 32 TIDF Compliance 2 non-null object 33 Existing Construction Type 155534 non-null float64 34 Existing Construction Type Description 155534 non-null object 35 Proposed Construction Type 155738 non-null float64 36 Proposed Construction Type Description 155738 non-null object 37 Site Permit 5359 non-null object 38 Supervisor District 197183 non-null float64 39 Neighborhoods - Analysis Boundaries 197175 non-null object 40 Zipcode 197184 non-null float64 41 Location 197200 non-null object 42 Record ID 198900 non-null int64<br />
dtypes: float64(12), int64(3), object(28) memory usage: 65.3+ MB</p>
<p>&lt;matplotlib.axes._subplots.AxesSubplot at 0x11a837550&gt;</p>
<div class="figure">
<img src="nb0007_data_cleaning_files/nb0007_data_cleaning_7_2.png" alt="png" />
<p class="caption">png</p>
</div>
</div>
</div>
<div id="data-cleaning-1" class="section level1">
<h1>Data Cleaning</h1>
<div id="step-1-getting-rid-of-extras-spaces" class="section level2">
<h2>Step 1 : Getting Rid Of Extras Spaces</h2>
<hr />
<pre class="python"><code>string = &quot;   hello world     &quot;

print(string)
print(&quot;=&quot;*100)

fresh_string = string.strip()
print(fresh_string)</code></pre>
<p>hello world<br />
==================================================================================================== hello world</p>
<p>The simple example here show that when there are unneeded spaces before the string and after the string, we want to make sure we can get rid of them.</p>
<p>The simple example illustrates how when there are extra spaces before and after strings, we want to ensure that we are getting rid of these unnecessary spaces.</p>
<p>The primary reason for wanting to clean our data set by removing the extra spaces is because these extra spaces will lead to both analytical and formatting issues down the road. For example, when performing logistic regression analysis, a string with extra spaces in the beginning like " hello" will be treated as a different factor in the system than a string with the extra space removed (“hello”), although they have the same meaning in real life.</p>
<p>We can apply the same methodology, as illustrated in the code above, to the entire data set.</p>
</div>
<div id="step-2-replacing-all-na-values" class="section level2">
<h2>Step 2 ：Replacing All NA Values</h2>
<hr />
<p>The second step is the most obvious step that we should do when it comes to cleaning our data set: removing the NA values that exist within the dataset. We want to replace these NA values with some value that will not influence the analytical results that we wish to do down the road. To do so, we can apply one of several techniques.</p>
<p>The first method is fast and easy. We can simply substitute all the NA values for 0. This method is advantageous to employ if we wish to sum the values down a column in our future analysis, as zeroes will not influence the resulting summation.</p>
<pre class="python"><code>test_row = mydata.iloc[0:5]
test_row.fillna(0, inplace=True)
test_row.head(1)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Permit Number
</th>
<th>
Permit Type
</th>
<th>
Permit Type Definition
</th>
<th>
Permit Creation Date
</th>
<th>
Block
</th>
<th>
Lot
</th>
<th>
Street Number
</th>
<th>
Street Number Suffix
</th>
<th>
Street Name
</th>
<th>
Street Suffix
</th>
<th>
…
</th>
<th>
Existing Construction Type
</th>
<th>
Existing Construction Type Description
</th>
<th>
Proposed Construction Type
</th>
<th>
Proposed Construction Type Description
</th>
<th>
Site Permit
</th>
<th>
Supervisor District
</th>
<th>
Neighborhoods - Analysis Boundaries
</th>
<th>
Zipcode
</th>
<th>
Location
</th>
<th>
Record ID
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
201505065519
</td>
<td>
4
</td>
<td>
sign - erect
</td>
<td>
05/06/2015
</td>
<td>
0326
</td>
<td>
023
</td>
<td>
140
</td>
<td>
0
</td>
<td>
Ellis
</td>
<td>
St
</td>
<td>
…
</td>
<td>
3.0
</td>
<td>
constr type 3
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
3.0
</td>
<td>
Tenderloin
</td>
<td>
94102.0
</td>
<td>
(37.785719256680785, -122.40852313194863)
</td>
<td>
1380611233945
</td>
</tr>
</tbody>
</table>
<p>
1 rows × 43 columns
</p>
</div>
<p>However, this methodology has its limitations. For example, we can see here that the Proposed Construction Type Description cannot be 0, so it would be inappropriate to treat this NA value as a 0. Being a description, the value here should be a string instead of number. So how do we want to handle scenarios where the data in a column are strings?</p>
<p>There is a simple method that can be applied: we can simply substitute the original NA value in the Proposed Construction Type Description with the value that appears most frequently in that column. This method is particularly useful in future analyses where we will be searching for any outliers within the dataframe. By using the value that appears most frequeuntly in the column, we will, again, not be interfering with future statistical analyses (searching for outliers).</p>
<pre class="python"><code>test_row = mydata.iloc[0:100]

test_row[&#39;Proposed Construction Type Description&#39;].fillna(test_row[&#39;Proposed Construction Type Description&#39;].value_counts()[:1].index.tolist()[0],inplace=True)
#using fillna command while inplace = true to replace the value
#test_row[&#39;Proposed Construction Type Description&#39;].value_counts()[:1].index.tolist()[0] returns the most frequent value appear with in the column
test_row.head(5)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Permit Number
</th>
<th>
Permit Type
</th>
<th>
Permit Type Definition
</th>
<th>
Permit Creation Date
</th>
<th>
Block
</th>
<th>
Lot
</th>
<th>
Street Number
</th>
<th>
Street Number Suffix
</th>
<th>
Street Name
</th>
<th>
Street Suffix
</th>
<th>
…
</th>
<th>
Existing Construction Type
</th>
<th>
Existing Construction Type Description
</th>
<th>
Proposed Construction Type
</th>
<th>
Proposed Construction Type Description
</th>
<th>
Site Permit
</th>
<th>
Supervisor District
</th>
<th>
Neighborhoods - Analysis Boundaries
</th>
<th>
Zipcode
</th>
<th>
Location
</th>
<th>
Record ID
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
201505065519
</td>
<td>
4
</td>
<td>
sign - erect
</td>
<td>
05/06/2015
</td>
<td>
0326
</td>
<td>
023
</td>
<td>
140
</td>
<td>
NaN
</td>
<td>
Ellis
</td>
<td>
St
</td>
<td>
…
</td>
<td>
3.0
</td>
<td>
constr type 3
</td>
<td>
NaN
</td>
<td>
wood frame (5)
</td>
<td>
NaN
</td>
<td>
3.0
</td>
<td>
Tenderloin
</td>
<td>
94102.0
</td>
<td>
(37.785719256680785, -122.40852313194863)
</td>
<td>
1380611233945
</td>
</tr>
<tr>
<th>
1
</th>
<td>
201604195146
</td>
<td>
4
</td>
<td>
sign - erect
</td>
<td>
04/19/2016
</td>
<td>
0306
</td>
<td>
007
</td>
<td>
440
</td>
<td>
NaN
</td>
<td>
Geary
</td>
<td>
St
</td>
<td>
…
</td>
<td>
3.0
</td>
<td>
constr type 3
</td>
<td>
NaN
</td>
<td>
wood frame (5)
</td>
<td>
NaN
</td>
<td>
3.0
</td>
<td>
Tenderloin
</td>
<td>
94102.0
</td>
<td>
(37.78733980600732, -122.41063199757738)
</td>
<td>
1420164406718
</td>
</tr>
<tr>
<th>
2
</th>
<td>
201605278609
</td>
<td>
3
</td>
<td>
additions alterations or repairs
</td>
<td>
05/27/2016
</td>
<td>
0595
</td>
<td>
203
</td>
<td>
1647
</td>
<td>
NaN
</td>
<td>
Pacific
</td>
<td>
Av
</td>
<td>
…
</td>
<td>
1.0
</td>
<td>
constr type 1
</td>
<td>
1.0
</td>
<td>
constr type 1
</td>
<td>
NaN
</td>
<td>
3.0
</td>
<td>
Russian Hill
</td>
<td>
94109.0
</td>
<td>
(37.7946573324287, -122.42232562979227)
</td>
<td>
1424856504716
</td>
</tr>
<tr>
<th>
3
</th>
<td>
201611072166
</td>
<td>
8
</td>
<td>
otc alterations permit
</td>
<td>
11/07/2016
</td>
<td>
0156
</td>
<td>
011
</td>
<td>
1230
</td>
<td>
NaN
</td>
<td>
Pacific
</td>
<td>
Av
</td>
<td>
…
</td>
<td>
5.0
</td>
<td>
wood frame (5)
</td>
<td>
5.0
</td>
<td>
wood frame (5)
</td>
<td>
NaN
</td>
<td>
3.0
</td>
<td>
Nob Hill
</td>
<td>
94109.0
</td>
<td>
(37.79595867909168, -122.41557405519474)
</td>
<td>
1443574295566
</td>
</tr>
<tr>
<th>
4
</th>
<td>
201611283529
</td>
<td>
6
</td>
<td>
demolitions
</td>
<td>
11/28/2016
</td>
<td>
0342
</td>
<td>
001
</td>
<td>
950
</td>
<td>
NaN
</td>
<td>
Market
</td>
<td>
St
</td>
<td>
…
</td>
<td>
3.0
</td>
<td>
constr type 3
</td>
<td>
NaN
</td>
<td>
wood frame (5)
</td>
<td>
NaN
</td>
<td>
6.0
</td>
<td>
Tenderloin
</td>
<td>
94102.0
</td>
<td>
(37.78315261897309, -122.40950883997789)
</td>
<td>
144548169992
</td>
</tr>
</tbody>
</table>
<p>
5 rows × 43 columns
</p>
</div>
<p>Notice how some of NAs in the Proposed Construction Type Description column have now successfully changed to “wood frame(5)”, which is the most frequent value of that column.</p>
</div>
<div id="step-3-converting-strings-into-numbers" class="section level2">
<h2>Step 3 : Converting Strings into Numbers</h2>
<hr />
<p>When we are performing numerical analysis, such as when we are finding the mean value, sometimes the system will return an error indicating what we cannot apply the mathematical command (finding the mean value) to a set of strings. In these cases, we want to make sure our data are in the correct format; that is, that our numbers are recorded as integers as opposed to strings, so that the data can be used for further numerical analysis.</p>
<p>Trying to convert strings into numbers in Excel can be a messy process; however, using Python, this conversion process is really simple to use to achieve our desired result. Here, we introcude two simple commands: “float” and “int”.</p>
<pre class="python"><code>test_row = mydata.iloc[0:5]
test_row[&#39;Permit Type&#39;].astype(float)</code></pre>
<p>0 4.0 1 4.0 2 3.0 3 8.0 4 6.0 Name: Permit Type, dtype: float64</p>
<pre class="python"><code>test_row = mydata.iloc[0:5]
test_row[&#39;Permit Type&#39;].astype(int)</code></pre>
<p>0 4 1 4 2 3 3 8 4 6 Name: Permit Type, dtype: int64</p>
<p>The “float” command converts a number so that it appears in scientific notation, while the “int” command converts a decimal number into an integer by rounding down. These two commands allow for flexibility in application.</p>
</div>
<div id="step-4-removing-unnecessary-duplicates" class="section level2">
<h2>Step 4 : Removing Unnecessary Duplicates</h2>
<hr />
<p>Sometimes, rows with same content will appear twice in our dataset, which is most likely undesirable for our dataset. How can we handle these unnecessary duplicates?</p>
<pre class="python"><code># create a sample df with 2 rows and fewer columns (for demonstration)
test_df = mydata[[&#39;Permit Number&#39;, &#39;Permit Type&#39;, &#39;Block&#39;]].iloc[0:2]
# create a df with double info
dup_df = pd.concat([test_df, test_df])
dup_df.head()

# just to demonstrate, see which rows have duplicates
dup_df[&#39;Duplicate&#39;] = dup_df.duplicated()
dup_df

# or if you have a unique identifier (like permit number) you can also use it to drop duplicates
# dup_df.drop_duplicates</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Permit Number
</th>
<th>
Permit Type
</th>
<th>
Block
</th>
<th>
Duplicate
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
201505065519
</td>
<td>
4
</td>
<td>
0326
</td>
<td>
False
</td>
</tr>
<tr>
<th>
1
</th>
<td>
201604195146
</td>
<td>
4
</td>
<td>
0306
</td>
<td>
False
</td>
</tr>
<tr>
<th>
0
</th>
<td>
201505065519
</td>
<td>
4
</td>
<td>
0326
</td>
<td>
True
</td>
</tr>
<tr>
<th>
1
</th>
<td>
201604195146
</td>
<td>
4
</td>
<td>
0306
</td>
<td>
True
</td>
</tr>
</tbody>
</table>
</div>
<p>Here, we see two rows that are duplicated, and we would like to remove these redundant rows. To do so, we use the “drop_duplicates” command to achieve our desired result: a data set that is free of unnecessary duplicates.</p>
<pre class="python"><code>test_df.drop_duplicates()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Permit Number
</th>
<th>
Permit Type
</th>
<th>
Block
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
201505065519
</td>
<td>
4
</td>
<td>
0326
</td>
</tr>
<tr>
<th>
1
</th>
<td>
201604195146
</td>
<td>
4
</td>
<td>
0306
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="step-5-finding-potential-mismatches" class="section level2">
<h2>Step 5 : Finding Potential Mismatches</h2>
<hr />
<p>The error seen in the following example is not the typical error seen in Python. This error refers more to a logical error in the data set, which we can better illustrate with the example below.</p>
<pre class="python"><code>test_df1 = mydata.iloc[0:5]
test_df1.head(1)</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Permit Number
</th>
<th>
Permit Type
</th>
<th>
Permit Type Definition
</th>
<th>
Permit Creation Date
</th>
<th>
Block
</th>
<th>
Lot
</th>
<th>
Street Number
</th>
<th>
Street Number Suffix
</th>
<th>
Street Name
</th>
<th>
Street Suffix
</th>
<th>
…
</th>
<th>
Existing Construction Type
</th>
<th>
Existing Construction Type Description
</th>
<th>
Proposed Construction Type
</th>
<th>
Proposed Construction Type Description
</th>
<th>
Site Permit
</th>
<th>
Supervisor District
</th>
<th>
Neighborhoods - Analysis Boundaries
</th>
<th>
Zipcode
</th>
<th>
Location
</th>
<th>
Record ID
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
201505065519
</td>
<td>
4
</td>
<td>
sign - erect
</td>
<td>
05/06/2015
</td>
<td>
0326
</td>
<td>
023
</td>
<td>
140
</td>
<td>
0
</td>
<td>
Ellis
</td>
<td>
St
</td>
<td>
…
</td>
<td>
3.0
</td>
<td>
constr type 3
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
3.0
</td>
<td>
Tenderloin
</td>
<td>
94102.0
</td>
<td>
(37.785719256680785, -122.40852313194863)
</td>
<td>
1380611233945
</td>
</tr>
</tbody>
</table>
<p>
1 rows × 43 columns
</p>
</div>
<p>So, what can be a potential mismatch in the dataframe?</p>
<p>Within our data set, we see one column labeled “Existing Construction Type” and another column labeled “Existing Constuction Type Description”. If we have an Existing Construction Type of 3.0, then we would expect that the corresponding Existing Construction Type Description to be “constr type 3”. What if, instead, the Existing Construction Type Description contained “constr type 4”?</p>
<p>In our data set, there is a fixed relationship between the Existing Construction Type and the Existing Construction Type Description. Any rows with differing values can be considered as an error, and we would want to correct this mismatch in our data cleaning process.</p>
<p>We can check our data set to see if there is any mismatching occurring in the first place:</p>
<pre class="python"><code>(mydata.groupby([&#39;Existing Construction Type&#39;, &#39;Existing Construction Type Description&#39;])
    .size()
    .reset_index()
    .rename(columns={0:&#39;count&#39;}))</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Existing Construction Type
</th>
<th>
Existing Construction Type Description
</th>
<th>
count
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1.0
</td>
<td>
constr type 1
</td>
<td>
28072
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2.0
</td>
<td>
constr type 2
</td>
<td>
4068
</td>
</tr>
<tr>
<th>
2
</th>
<td>
3.0
</td>
<td>
constr type 3
</td>
<td>
9663
</td>
</tr>
<tr>
<th>
3
</th>
<td>
4.0
</td>
<td>
constr type 4
</td>
<td>
381
</td>
</tr>
<tr>
<th>
4
</th>
<td>
5.0
</td>
<td>
wood frame (5)
</td>
<td>
113350
</td>
</tr>
</tbody>
</table>
</div>
<p>Let’s assume some mismatching problems actually occur in our data set. We can apply the following technique to correct for any of mismatching errors between the Existing Construction Type data and the Existing Construction Type Description data:</p>
<pre class="python"><code>test_df1[&quot;Existing Construction Type&quot;].unique()
print(&quot;There are 3 Existing Construction Types, which are 1, 3, and 5&quot;)
print()
print(&quot;=&quot;*100)
print()

def errorcheck(a):
    if a[&quot;Existing Construction Type&quot;] == 3.0:
        a[&quot;Existing Construction Type Description&quot;] = &quot;constr type 3&quot;
    if a[&quot;Existing Construction Type&quot;] == 1.0:
        a[&quot;Existing Construction Type Description&quot;] = &quot;constr type 1&quot;
    if a[&quot;Existing Construction Type&quot;] == 5.0:
        a[&quot;Existing Construction Type Description&quot;] = &quot;wood frame (5)&quot;</code></pre>
<hr />
<p>NameError Traceback (most recent call last)</p>
<p><ipython-input-4-50dd5b06296e> in <module> —-&gt; 1 test_df1[“Existing Construction Type”].unique() 2 print(“There are 3 Existing Construction Types, which are 1, 3, and 5”) 3 print() 4 print(“=”*100) 5 print()</p>
<p>NameError: name ‘test_df1’ is not defined</p>
<pre class="python"><code>for index, row in test_row.iterrows():
    errorcheck(row)
test_row.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Permit Number
</th>
<th>
Permit Type
</th>
<th>
Permit Type Definition
</th>
<th>
Permit Creation Date
</th>
<th>
Block
</th>
<th>
Lot
</th>
<th>
Street Number
</th>
<th>
Street Number Suffix
</th>
<th>
Street Name
</th>
<th>
Street Suffix
</th>
<th>
…
</th>
<th>
Existing Construction Type
</th>
<th>
Existing Construction Type Description
</th>
<th>
Proposed Construction Type
</th>
<th>
Proposed Construction Type Description
</th>
<th>
Site Permit
</th>
<th>
Supervisor District
</th>
<th>
Neighborhoods - Analysis Boundaries
</th>
<th>
Zipcode
</th>
<th>
Location
</th>
<th>
Record ID
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
201505065519
</td>
<td>
4
</td>
<td>
sign - erect
</td>
<td>
05/06/2015
</td>
<td>
0326
</td>
<td>
023
</td>
<td>
140
</td>
<td>
0
</td>
<td>
ellis
</td>
<td>
St
</td>
<td>
…
</td>
<td>
3.0
</td>
<td>
constr type 3
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
3.0
</td>
<td>
Tenderloin
</td>
<td>
94102.0
</td>
<td>
(37.785719256680785, -122.40852313194863)
</td>
<td>
1380611233945
</td>
</tr>
<tr>
<th>
1
</th>
<td>
201604195146
</td>
<td>
4
</td>
<td>
sign - erect
</td>
<td>
04/19/2016
</td>
<td>
0306
</td>
<td>
007
</td>
<td>
440
</td>
<td>
0
</td>
<td>
geary
</td>
<td>
St
</td>
<td>
…
</td>
<td>
3.0
</td>
<td>
constr type 3
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
3.0
</td>
<td>
Tenderloin
</td>
<td>
94102.0
</td>
<td>
(37.78733980600732, -122.41063199757738)
</td>
<td>
1420164406718
</td>
</tr>
<tr>
<th>
2
</th>
<td>
201605278609
</td>
<td>
3
</td>
<td>
additions alterations or repairs
</td>
<td>
05/27/2016
</td>
<td>
0595
</td>
<td>
203
</td>
<td>
1647
</td>
<td>
0
</td>
<td>
pacific
</td>
<td>
Av
</td>
<td>
…
</td>
<td>
1.0
</td>
<td>
constr type 1
</td>
<td>
1.0
</td>
<td>
constr type 1
</td>
<td>
0
</td>
<td>
3.0
</td>
<td>
Russian Hill
</td>
<td>
94109.0
</td>
<td>
(37.7946573324287, -122.42232562979227)
</td>
<td>
1424856504716
</td>
</tr>
<tr>
<th>
3
</th>
<td>
201611072166
</td>
<td>
8
</td>
<td>
otc alterations permit
</td>
<td>
11/07/2016
</td>
<td>
0156
</td>
<td>
011
</td>
<td>
1230
</td>
<td>
0
</td>
<td>
pacific
</td>
<td>
Av
</td>
<td>
…
</td>
<td>
5.0
</td>
<td>
wood frame (5)
</td>
<td>
5.0
</td>
<td>
wood frame (5)
</td>
<td>
0
</td>
<td>
3.0
</td>
<td>
Nob Hill
</td>
<td>
94109.0
</td>
<td>
(37.79595867909168, -122.41557405519474)
</td>
<td>
1443574295566
</td>
</tr>
<tr>
<th>
4
</th>
<td>
201611283529
</td>
<td>
6
</td>
<td>
demolitions
</td>
<td>
11/28/2016
</td>
<td>
0342
</td>
<td>
001
</td>
<td>
950
</td>
<td>
0
</td>
<td>
market
</td>
<td>
St
</td>
<td>
…
</td>
<td>
3.0
</td>
<td>
constr type 3
</td>
<td>
0.0
</td>
<td>
0
</td>
<td>
0
</td>
<td>
6.0
</td>
<td>
Tenderloin
</td>
<td>
94102.0
</td>
<td>
(37.78315261897309, -122.40950883997789)
</td>
<td>
144548169992
</td>
</tr>
</tbody>
</table>
<p>
5 rows × 43 columns
</p>
</div>
<pre class="python"><code>#there are alternative methods for doing this cleaning
#or use apply and lambda with a simplified function

# a simpler function 

def constr_type(x):
    if x == 3.0:
        descr = &quot;constr type 3&quot;
    elif x == 1.0:
        descr = &quot;constr type 1&quot;
    elif x == 5.0:
        descr = &quot;wood frame (5)&quot;
    else:
        descr = None
    return(descr)

new_df = test_df1
new_df[&#39;New Description&#39;] = new_df[&#39;Existing Construction Type&#39;].apply(lambda x: constr_type(x))


# or you can map a dictionary
constr_dict = {1.0: &quot;constr type 1&quot;,
              3.0: &quot;constr type 3&quot;,
              5.0: &quot;wood frame (5)&quot;}

new_df[&#39;New Description2&#39;] = new_df[&#39;Existing Construction Type&#39;].map(constr_dict)
new_df</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Permit Number
</th>
<th>
Permit Type
</th>
<th>
Permit Type Definition
</th>
<th>
Permit Creation Date
</th>
<th>
Block
</th>
<th>
Lot
</th>
<th>
Street Number
</th>
<th>
Street Number Suffix
</th>
<th>
Street Name
</th>
<th>
Street Suffix
</th>
<th>
…
</th>
<th>
Proposed Construction Type
</th>
<th>
Proposed Construction Type Description
</th>
<th>
Site Permit
</th>
<th>
Supervisor District
</th>
<th>
Neighborhoods - Analysis Boundaries
</th>
<th>
Zipcode
</th>
<th>
Location
</th>
<th>
Record ID
</th>
<th>
New Description
</th>
<th>
New Description2
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
201505065519
</td>
<td>
4
</td>
<td>
sign - erect
</td>
<td>
05/06/2015
</td>
<td>
0326
</td>
<td>
023
</td>
<td>
140
</td>
<td>
NaN
</td>
<td>
Ellis
</td>
<td>
St
</td>
<td>
…
</td>
<td>
NaN
</td>
<td>
wood frame (5)
</td>
<td>
NaN
</td>
<td>
3.0
</td>
<td>
Tenderloin
</td>
<td>
94102.0
</td>
<td>
(37.785719256680785, -122.40852313194863)
</td>
<td>
1380611233945
</td>
<td>
constr type 3
</td>
<td>
constr type 3
</td>
</tr>
<tr>
<th>
1
</th>
<td>
201604195146
</td>
<td>
4
</td>
<td>
sign - erect
</td>
<td>
04/19/2016
</td>
<td>
0306
</td>
<td>
007
</td>
<td>
440
</td>
<td>
NaN
</td>
<td>
Geary
</td>
<td>
St
</td>
<td>
…
</td>
<td>
NaN
</td>
<td>
wood frame (5)
</td>
<td>
NaN
</td>
<td>
3.0
</td>
<td>
Tenderloin
</td>
<td>
94102.0
</td>
<td>
(37.78733980600732, -122.41063199757738)
</td>
<td>
1420164406718
</td>
<td>
constr type 3
</td>
<td>
constr type 3
</td>
</tr>
</tbody>
</table>
<p>
2 rows × 45 columns
</p>
</div>
</div>
<div id="step-6-using-consistent-upperlower-cases" class="section level2">
<h2>Step 6 : Using Consistent Upper/Lower Cases</h2>
<hr />
<p>While this step may be less relevant to our construction data set, there are many reasons why upper and lower cases should be considered in data cleaning. There may have been human errors while inputing the data, and some NLP algorithms consider upper cases in data as a factor in expressing strong opinions. Therefore, we want to ensure that we are being cautious with the usage of upper and/or lower cases in our data set.</p>
<p>One universal way to remove the case influence in data is to first change all values to upper case, and then change them all back to lower case again. This ensures that all our data are, in fact, consistently in lower case.</p>
<p>In the following example, we may want to remove the capitalization at the beginning of each street name. To remove this capitalization, we will first change all the street names into upper case, and then change them back to be in only lower case.</p>
<pre class="python"><code>test_row = mydata.iloc[0:5]
test_row[&quot;Street Name&quot;] = test_row[&quot;Street Name&quot;].str.upper();print(test_row[&quot;Street Name&quot;] )</code></pre>
<p>0 ELLIS 1 GEARY 2 PACIFIC 3 PACIFIC 4 MARKET Name: Street Name, dtype: object</p>
<pre class="python"><code>test_row[&quot;Street Name&quot;] = test_row[&quot;Street Name&quot;].str.lower();print(test_row[&quot;Street Name&quot;] )</code></pre>
<p>0 ellis 1 geary 2 pacific 3 pacific 4 market Name: Street Name, dtype: object</p>
<p>Using this universal method, there are no more upper cases left in the street name data. In the future, NLP algorithms can be applied to this clean data set.</p>
</div>
</div>
<div id="next-step" class="section level1">
<h1>Next Step</h1>
<p><a href="https://www.digitalvidya.com/blog/data-cleaning-techniques/" class="uri">https://www.digitalvidya.com/blog/data-cleaning-techniques/</a></p>
<p><a href="https://www.kaggle.com/rtatman/data-cleaning-challenge-handling-missing-values" class="uri">https://www.kaggle.com/rtatman/data-cleaning-challenge-handling-missing-values</a></p>
<p><a href="https://www.geeksforgeeks.org/python-pandas-dataframe-drop_duplicates/" class="uri">https://www.geeksforgeeks.org/python-pandas-dataframe-drop_duplicates/</a></p>
<p><a href="https://stackabuse.com/removing-stop-words-from-strings-in-python/#" class="uri">https://stackabuse.com/removing-stop-words-from-strings-in-python/#</a>:~:text=To%20remove%20stop%20words%20from%20a%20sentence%2C%20you%20can%20divide,stop%20words%20provided%20by%20NLTK.&amp;text=In%20the%20script%20above%2C%20we,()%20method%20from%20the%20nltk.</p>
</div>

<div class="footer">
  <p style="text-align: center;line-height: 1.5;font-size: 15px;">
    Created and maintained by the <a href="https://www.sauder.ubc.ca/programs/masters-degrees/mban">Master of Business Analytics</a> Community. <br> Licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>. <br>
  </p>
</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
