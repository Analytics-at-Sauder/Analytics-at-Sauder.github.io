<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>nb0008_sales_forecast_part_2.utf8</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/simplex.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<!-- Google Tag Manager -->

<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-NFJ7QKG');</script>

<!-- End Google Tag Manager -->

<!-- Script hiding navbar when scrolling down -->

<script>
  var didScroll;
  var lastScrollTop = 0;
  var delta = 1;
  var navbarHeight = $('[role="navigation"]').outerHeight();

  $(window).scroll(function(event) {
    didScroll = true;
  });

  setInterval(function() {
    if (didScroll) {
      hasScrolled();
      didScroll = false;
    }
  }, 250);

  function hasScrolled() {
    var st = $(this).scrollTop();

    if (Math.abs(lastScrollTop - st) <= delta)
      return;

    if (st > lastScrollTop && st > navbarHeight) {
      // Scroll Down
      $('[role="navigation"]').addClass('navbar-scroll-down');
    } else {
      // Scroll Up
      if (st + $(window).height() < $(document).height()) {
        $('[role="navigation"]').removeClass('navbar-scroll-down');
      }
    }

    lastScrollTop = st;
  }
</script>

<!-- End of script hiding navbar when scrolling down -->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 41px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 46px;
  margin-top: -46px;
}
.section h2 {
  padding-top: 46px;
  margin-top: -46px;
}
.section h3 {
  padding-top: 46px;
  margin-top: -46px;
}
.section h4 {
  padding-top: 46px;
  margin-top: -46px;
}
.section h5 {
  padding-top: 46px;
  margin-top: -46px;
}
.section h6 {
  padding-top: 46px;
  margin-top: -46px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Analytics@Sauder</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="contribute.html">Contribute</a>
</li>
<li>
  <a href="https://blogs.ubc.ca/businessanalytics">Blog</a>
</li>
<li>
  <a href="projects.html">Projects</a>
</li>
<li>
  <a href="resources.html">Resource</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<!-- Google Tag Manager (noscript) -->

<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NFJ7QKG"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

<!-- End Google Tag Manager (noscript) -->

<div class="fluid-row" id="header">




</div>


<div id="sales-forecaset-part-2" class="section level2">
<h2>Sales Forecaset (Part 2)</h2>
<div id="author-charlie-cao" class="section level4">
<h4>Author: Charlie Cao</h4>
<p>This is the second of a series of two notebooks on the topic of Sales Forecast. Through this series, we want to showcase one of the many ways that one can follow exloring and forecasting time series data. We encourage you to create your own Jupytor Notebook and follow along. You can also download this notebook along with any accompanying data in the <a href="https://github.com/Master-of-Business-Analytics/Notebooks_and_Data">Notebooks and Data</a> GitHub Repository. Alternatively, if you do not have Python or Jupyter Notebook installed yet, you may experiment with a virtual Notebook by launching Binder or Syzygy below (learn more about these two tools in the <a href="https://analytics-at-sauder.github.io/resource.html">Resource</a> tab).</p>
<p><a href="https://ubc.syzygy.ca/jupyter/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2FAnalytics-at-Sauder%2FNB0008_Sales_Forecast&urlpath=tree%2FNB0008_Sales_Forecast%2Fnb0008_sales_forecast_part_2.ipynb&branch=master" target="_blank" class="button">Launch Syzygy (UBC)</a></p>
<p><a href="https://pims.syzygy.ca/jupyter/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2FAnalytics-at-Sauder%2FNB0008_Sales_Forecast&urlpath=tree%2FNB0008_Sales_Forecast%2Fnb0008_sales_forecast_part_2.ipynb&branch=master" target="_blank" class="button">Launch Syzygy (Google)</a></p>
<p><a href="https://mybinder.org/v2/gh/Analytics-at-Sauder/NB0008_Sales_Forecast/master?filepath=nb0008_sales_forecast_part_2.ipynb" target="_blank" class="button">Launch Binder</a></p>
</div>
</div>
<div id="background" class="section level2">
<h2>Background</h2>
<hr />
<p>The previous Notebook provides a detailed guide on the exploration and manipulation of data, while this Notebook will be centered around the modeling process itself. Understanding the data is important for analytics, and we recommend that you read the first Notebook (Part 1) prior to diving into modeling in order to gain a better grasp of our large and messy data. The datasets that we are using consist of sales records for a retailer with 45 stores, each containing several departments. They are already included in the GitHub Repository where this Jupyter Notebook is located (please see the “Data” folder), but you can also find them on <a href="https://www.kaggle.com/manjeetsingh/retaildataset?select=sales+data-set.csv">this Kaggle page</a>.</p>
<p>Let’s first start by importing the libraries we need and loading our data:</p>
<pre class="python"><code>import pandas as pd
import numpy as np
import datetime
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.seasonal import STL
from statsmodels.graphics.tsaplots import plot_acf
# Prophet is a forecasting package developed by Facebook
from fbprophet import Prophet
# ipywidgets are used to make interactive contents in Jupyter notebooks
from ipywidgets import interact

# There are multiple SettingWithCopyWarnings in this notebook
# Read more here:
# https://www.dataquest.io/blog/settingwithcopywarning/
# https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

# import data
df_sales = pd.read_csv(&#39;nb0008_data/sales.csv&#39;)
df_features = pd.read_csv(&#39;nb0008_data/features.csv&#39;)
df_stores = pd.read_csv(&#39;nb0008_data/stores.csv&#39;)

# converting the date column (initally stored as strings) to dates
df_sales[&#39;Date&#39;] = pd.to_datetime(df_sales[&#39;Date&#39;], format=&#39;%d/%m/%Y&#39;)
df_features[&#39;Date&#39;] = pd.to_datetime(df_features[&#39;Date&#39;], format=&#39;%d/%m/%Y&#39;)

# converting categorical-numeric columns to categories, which increases run speed
df_sales[&#39;Store&#39;] = df_sales[&#39;Store&#39;].astype(&#39;category&#39;)
df_sales[&#39;Dept&#39;] = df_sales[&#39;Dept&#39;].astype(&#39;category&#39;)
df_features[&#39;Store&#39;] = df_features[&#39;Store&#39;].astype(&#39;category&#39;)
df_stores[&#39;Store&#39;] = df_stores[&#39;Store&#39;].astype(&#39;category&#39;)
df_stores[&#39;Type&#39;] = df_stores[&#39;Type&#39;].astype(&#39;category&#39;)</code></pre>
</div>
<div id="modeling" class="section level2">
<h2>Modeling</h2>
<hr />
<p>In this Notebook, we will be using the <code>Prophet</code> forecasting package developed by Facebook. However, there are many other forecasting methods and packages, such as ARIMA models, ETS models, or a combination of explanatory models (linear regression) and time series models; some machine learning models can also be used to predict time series. After reading this Notebook, we encourage you to experiment with different forecasting packages in Python (or R) so that you can find the best fit for your data.</p>
<div id="stl-decomposition" class="section level3">
<h3>STL Decomposition</h3>
<p>Time series data can usually be described with Trend, Cycle, and Seasonality. The book, “Forecasting: Principles and Practice”, does a great job defining these three components in <a href="https://otexts.com/fpp2/tspatterns.html">Chapter 2.3</a>. Oftentimes, identifying these components in our data (and understanding our data in general) can help us select the most appropriate model(s). There are many different ways to decompose time series data. STL decomposition (short for Seasonal and Trend decomposition using Loess) is helpful in our case because we have weekly data, while a lot of other decomposition methods are only applicable to monthly or quarterly data. Here, we utilize <code>ipywidgets</code> again (please read its <a href="https://ipywidgets.readthedocs.io/en/latest/">documentation</a> for more information or for tutorials), together with the <code>STL</code> function from <code>statsmodels</code>, to inspect the different trends and seasonalities across stores and departments:</p>
<pre class="python"><code>def stl_viz(store_num, dept_num):
    try:
        # Subsetting data according to store and department number
        sales_temp = df_sales[(df_sales.Store==store_num)&amp;(df_sales.Dept==dept_num)]
        # Transform dataframe into time series
        sales_temp_ts = sales_temp.set_index(&#39;Date&#39;)[&#39;Weekly_Sales&#39;]
        # Decompose the data
        stl_temp = STL(sales_temp_ts).fit()
        # Set up plot
        plt.rc(&#39;figure&#39;,figsize=(12,8))
        plot_temp = stl_temp.plot()
        plt.show()
        return 
    except:
        # Error message for when store-department combination doesn&#39;t exist
        print(&quot;ERROR: There is no Department {} in Store {}&quot;.format(store_num, dept_num))
        return

display(interact(stl_viz, store_num={n:n for n in range(1,46)}, dept_num={n:n for n in range(1,100)}))</code></pre>
<pre><code>interactive(children=(Dropdown(description=&#39;store_num&#39;, options={1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: …



&lt;function __main__.stl_viz(store_num, dept_num)&gt;</code></pre>
</div>
<div id="prophet" class="section level3">
<h3>Prophet</h3>
<p>Prophet is a package developed by Facebook. It is fast and fully automatic, which might not always be the best, but it surely is convenient. Prophet is also compatible with weekly data, which is one of the main reasons for why we are using it in this case; many other models, such as ARIMA and ETS models, only take in integer seasonalities (for example: 12), whereas the number of weeks in a year is usually not an integer (approximately 52.14). Prophet allows users to specify holidays in the model, as well, so that unusual observations caused by holidays can also be modeled. Let’s start by building a model for Department 1 in Store 1.</p>
<p>First, we will create a subset of the <code>sales</code> dataframe for rows where the <code>Store</code> and the <code>Dept</code> columns are both equal to 1:</p>
<pre class="python"><code>sales_s1d1_df = df_sales[(df_sales.Store==1)&amp;(df_sales.Dept==1)]

# Taking the log of `Weekly_Sales` so that it is less right skewed
sales_s1d1_df.loc[:,&#39;Log_Weekly_Sales&#39;] = np.log(sales_s1d1_df.loc[:,&#39;Weekly_Sales&#39;])

sales_s1d1_df.head()</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Store
</th>
<th>
Dept
</th>
<th>
Date
</th>
<th>
Weekly_Sales
</th>
<th>
IsHoliday
</th>
<th>
Log_Weekly_Sales
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
1
</td>
<td>
2010-02-05
</td>
<td>
24924.50
</td>
<td>
False
</td>
<td>
10.123607
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
1
</td>
<td>
2010-02-12
</td>
<td>
46039.49
</td>
<td>
True
</td>
<td>
10.737255
</td>
</tr>
<tr>
<th>
2
</th>
<td>
1
</td>
<td>
1
</td>
<td>
2010-02-19
</td>
<td>
41595.55
</td>
<td>
False
</td>
<td>
10.635748
</td>
</tr>
<tr>
<th>
3
</th>
<td>
1
</td>
<td>
1
</td>
<td>
2010-02-26
</td>
<td>
19403.54
</td>
<td>
False
</td>
<td>
9.873211
</td>
</tr>
<tr>
<th>
4
</th>
<td>
1
</td>
<td>
1
</td>
<td>
2010-03-05
</td>
<td>
21827.90
</td>
<td>
False
</td>
<td>
9.990944
</td>
</tr>
</tbody>
</table>
</div>
<div id="traintest-split" class="section level4">
<h4>Train/Test Split</h4>
<p>Just like a lot of machine learning models, we want to split our data into training and testing sets (commonly 80% and 20%, respectively) before we build our models so that we can evaluate the performance of these models. In our case, even though we do not have a lot of data to work with (two years of data with yearly seasonality), we still want to have at least an entire year of data in our test set so that we can evaluate the performance of our model across seasons. From the first Notebook, we know that the last date in our dataset is ‘2012-10-26’, so we will set the cutoff line exactly a year before that date. Note that you must use a date that exists in the data to keep the weekly intervals consistent. Prophet is very particular about the data that it uses: the date column has to be named <code>ds</code> while the dependent variable should be named <code>y</code>, and we will format our dataframe accordingly.</p>
<pre class="python"><code># Define threshold date and creating a threashold filter
threshold_date = pd.to_datetime(&#39;2011-10-28&#39;)
threshold = sales_s1d1_df.Date &lt;= threshold_date

# Splitting the original dataframe into training and testing sets for residual diagnosis later
sales_s1d1_df_train = sales_s1d1_df[threshold]
sales_s1d1_df_test = sales_s1d1_df[~threshold]


sales_s1d1_train = (sales_s1d1_df_train[[&#39;Date&#39;, &#39;Log_Weekly_Sales&#39;]]
                    .rename(columns={&#39;Date&#39;:&#39;ds&#39;, &#39;Log_Weekly_Sales&#39;: &#39;y&#39;}))
sales_s1d1_test = (sales_s1d1_df_test[[&#39;Date&#39;, &#39;Log_Weekly_Sales&#39;]]
                   .rename(columns={&#39;Date&#39;:&#39;ds&#39;, &#39;Log_Weekly_Sales&#39;: &#39;y&#39;}))

display(sales_s1d1_train.head())
print(&#39;ATTENTION: Training set has {} rows&#39;.format(sales_s1d1_train.shape[0]))
display(sales_s1d1_test.head())
print(&#39;ATTENTION: Testing set has {} rows&#39;.format(sales_s1d1_test.shape[0]))</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
ds
</th>
<th>
y
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
2010-02-05
</td>
<td>
10.123607
</td>
</tr>
<tr>
<th>
1
</th>
<td>
2010-02-12
</td>
<td>
10.737255
</td>
</tr>
<tr>
<th>
2
</th>
<td>
2010-02-19
</td>
<td>
10.635748
</td>
</tr>
<tr>
<th>
3
</th>
<td>
2010-02-26
</td>
<td>
9.873211
</td>
</tr>
<tr>
<th>
4
</th>
<td>
2010-03-05
</td>
<td>
9.990944
</td>
</tr>
</tbody>
</table>
</div>
<p>ATTENTION: Training set has 91 rows</p>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
ds
</th>
<th>
y
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
91
</th>
<td>
2011-11-04
</td>
<td>
10.593782
</td>
</tr>
<tr>
<th>
92
</th>
<td>
2011-11-11
</td>
<td>
9.835719
</td>
</tr>
<tr>
<th>
93
</th>
<td>
2011-11-18
</td>
<td>
9.854857
</td>
</tr>
<tr>
<th>
94
</th>
<td>
2011-11-25
</td>
<td>
9.948043
</td>
</tr>
<tr>
<th>
95
</th>
<td>
2011-12-02
</td>
<td>
10.138302
</td>
</tr>
</tbody>
</table>
</div>
<p>ATTENTION: Testing set has 52 rows</p>
<pre class="python"><code># Visualize train/test split
plt.rc(&#39;figure&#39;,figsize=(15,5))
fig, ax = plt.subplots()

sns.lineplot(x=&#39;ds&#39;, y=&#39;y&#39;, label=&#39;train&#39;, data=sales_s1d1_train, ax=ax)
sns.lineplot(x=&#39;ds&#39;, y=&#39;y&#39;, label=&#39;test&#39;, data=sales_s1d1_test, ax=ax)

# A vertical gray dashed line seperating the training and testing sets
ax.axvline(threshold_date, color=&#39;grey&#39;, linestyle=&#39;--&#39;)

ax.legend(loc=&#39;upper right&#39;)
ax.set(title=&#39;Weekly Sales&#39;, ylabel=&#39;&#39;);</code></pre>
<div class="figure">
<img src="nb0008_sales_forecast_part_2_files/nb0008_sales_forecast_part_2_8_0.png" alt="png" />
<p class="caption">png</p>
</div>
</div>
<div id="holidays" class="section level4">
<h4>Holidays</h4>
<p>To model holidays in Prophet, we have to create a similar time series dataframe, with the names of the holidays in the <code>holiday</code> column and the date, again, in the <code>ds</code> column. Here, we create this dataframe accordingly:</p>
<pre class="python"><code># Subsetting data where the `IsHoliday` column indicates that the observation is a holiday
holidays_s1d1_df = sales_s1d1_df[sales_s1d1_df.IsHoliday==True]
# Create new dataframe with only `ds` and `holiday` columns
holidays_s1d1 = pd.DataFrame({&#39;ds&#39;:holidays_s1d1_df[&#39;Date&#39;], &#39;holiday&#39;:&#39;holiday&#39;})
display(holidays_s1d1.head())</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
ds
</th>
<th>
holiday
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1
</th>
<td>
2010-02-12
</td>
<td>
holiday
</td>
</tr>
<tr>
<th>
31
</th>
<td>
2010-09-10
</td>
<td>
holiday
</td>
</tr>
<tr>
<th>
42
</th>
<td>
2010-11-26
</td>
<td>
holiday
</td>
</tr>
<tr>
<th>
47
</th>
<td>
2010-12-31
</td>
<td>
holiday
</td>
</tr>
<tr>
<th>
53
</th>
<td>
2011-02-11
</td>
<td>
holiday
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="fitting" class="section level4">
<h4>Fitting</h4>
<p>Now that we have our datasets ready, we can finally fit the model. One of the parameters of the model is called <code>mcmc_samples</code>, which sepcifies the number of samples to draw using the <a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">Markov Chain Monte Carlo</a> method; this parameter has an impact on the confidence interval of our model, but for simplicity, we will not get into further details for the purposes of this Notebook.</p>
<pre class="python"><code>model = Prophet(yearly_seasonality=True, 
                weekly_seasonality=False, 
                daily_seasonality=False, 
                holidays=holidays_s1d1, 
                interval_width=0.95, 
                mcmc_samples=100)

model.fit(sales_s1d1_train)

# Warning messages might appear in our case because of limited data</code></pre>
<pre><code>    WARNING:pystan:n_eff / iter below 0.001 indicates that the effective sample size has likely been overestimated
    WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed
    WARNING:pystan:10 of 200 iterations saturated the maximum tree depth of 10 (5 %)
    WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation
    




    &lt;fbprophet.forecaster.Prophet at 0x1e5ad4e1d88&gt;</code></pre>
</div>
</div>
</div>
<div id="testing-the-model" class="section level2">
<h2>Testing the Model</h2>
<hr />
<p>Now with the model fitted using our training set, we can forecast our test set and compare it with the observed data. In this step, we will be able to analyze the errors of our forecasts and calculate some useful metrics for the model, which can be later used to compare with other models. Note that Prophet also generates retrospective predictions for past data, but we will only be using ‘future’ data, which is our test set.</p>
<pre class="python"><code># Create a new dataframe containing current dates and future dates
# Make sure to use &quot;7D&quot; instead of &quot;W&quot; as the frequency so the intervals stay the same
future = model.make_future_dataframe(periods=sales_s1d1_test.shape[0], freq=&#39;7D&#39;)
# Generate predictions. 
forecast = model.predict(df=future)

# Back-transform the predictions and confidence intervals
forecast.loc[:,&#39;exp_yhat&#39;] = np.exp(forecast.loc[:,&#39;yhat&#39;])
forecast.loc[:,&#39;exp_yhat_upper&#39;] = np.exp(forecast.loc[:,&#39;yhat_upper&#39;])
forecast.loc[:,&#39;exp_yhat_lower&#39;] = np.exp(forecast.loc[:,&#39;yhat_lower&#39;])

# Creating a threshold filter and subset the &#39;future&#39; forecasted data
threshold_forecast = forecast.ds &lt;= threshold_date
forecast_test = forecast[~threshold_forecast]

display(forecast_test.head())
# Scroll to the right for back-transformed forecasts</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
ds
</th>
<th>
trend
</th>
<th>
yhat_lower
</th>
<th>
yhat_upper
</th>
<th>
trend_lower
</th>
<th>
trend_upper
</th>
<th>
additive_terms
</th>
<th>
additive_terms_lower
</th>
<th>
additive_terms_upper
</th>
<th>
holiday
</th>
<th>
…
</th>
<th>
yearly
</th>
<th>
yearly_lower
</th>
<th>
yearly_upper
</th>
<th>
multiplicative_terms
</th>
<th>
multiplicative_terms_lower
</th>
<th>
multiplicative_terms_upper
</th>
<th>
yhat
</th>
<th>
exp_yhat
</th>
<th>
exp_yhat_upper
</th>
<th>
exp_yhat_lower
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
91
</th>
<td>
2011-11-04
</td>
<td>
9.827337
</td>
<td>
9.721947
</td>
<td>
10.865659
</td>
<td>
9.528802
</td>
<td>
10.089194
</td>
<td>
0.411530
</td>
<td>
0.149102
</td>
<td>
0.654354
</td>
<td>
0.0
</td>
<td>
…
</td>
<td>
0.411530
</td>
<td>
0.149102
</td>
<td>
0.654354
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
10.238867
</td>
<td>
27969.413170
</td>
<td>
52347.464653
</td>
<td>
16679.687463
</td>
</tr>
<tr>
<th>
92
</th>
<td>
2011-11-11
</td>
<td>
9.820663
</td>
<td>
9.357288
</td>
<td>
10.587088
</td>
<td>
9.496571
</td>
<td>
10.101078
</td>
<td>
0.128629
</td>
<td>
-0.157932
</td>
<td>
0.415835
</td>
<td>
0.0
</td>
<td>
…
</td>
<td>
0.128629
</td>
<td>
-0.157932
</td>
<td>
0.415835
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
9.949291
</td>
<td>
20937.382581
</td>
<td>
39619.965889
</td>
<td>
11582.927667
</td>
</tr>
<tr>
<th>
93
</th>
<td>
2011-11-18
</td>
<td>
9.813988
</td>
<td>
9.087429
</td>
<td>
10.221261
</td>
<td>
9.472173
</td>
<td>
10.106962
</td>
<td>
-0.158051
</td>
<td>
-0.420778
</td>
<td>
0.129869
</td>
<td>
0.0
</td>
<td>
…
</td>
<td>
-0.158051
</td>
<td>
-0.420778
</td>
<td>
0.129869
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
9.655937
</td>
<td>
15614.214987
</td>
<td>
27481.312068
</td>
<td>
8843.420350
</td>
</tr>
<tr>
<th>
94
</th>
<td>
2011-11-25
</td>
<td>
9.807314
</td>
<td>
8.974859
</td>
<td>
10.184661
</td>
<td>
9.454328
</td>
<td>
10.116060
</td>
<td>
-0.202560
</td>
<td>
-0.453042
</td>
<td>
0.107089
</td>
<td>
0.0
</td>
<td>
…
</td>
<td>
-0.202560
</td>
<td>
-0.453042
</td>
<td>
0.107089
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
9.604754
</td>
<td>
14835.139555
</td>
<td>
26493.660239
</td>
<td>
7901.904417
</td>
</tr>
<tr>
<th>
95
</th>
<td>
2011-12-02
</td>
<td>
9.800639
</td>
<td>
9.207331
</td>
<td>
10.462551
</td>
<td>
9.427982
</td>
<td>
10.127377
</td>
<td>
0.063334
</td>
<td>
-0.195558
</td>
<td>
0.356669
</td>
<td>
0.0
</td>
<td>
…
</td>
<td>
0.063334
</td>
<td>
-0.195558
</td>
<td>
0.356669
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
9.863973
</td>
<td>
19225.119960
</td>
<td>
34980.678991
</td>
<td>
9969.955755
</td>
</tr>
</tbody>
</table>
<p>
5 rows × 25 columns
</p>
</div>
<pre class="python"><code>fig, ax = plt.subplots()
plt.rc(&#39;figure&#39;,figsize=(20,5))

sns.lineplot(x=&#39;Date&#39;, y=&#39;Weekly_Sales&#39;, label=&#39;train&#39;, data=sales_s1d1_df_train, ax=ax)
sns.lineplot(x=&#39;Date&#39;, y=&#39;Weekly_Sales&#39;, label=&#39;test&#39;, data=sales_s1d1_df_test, ax=ax)
sns.lineplot(x=&#39;ds&#39;, y=&#39;exp_yhat&#39;, label=&#39;prediction&#39;, data=forecast_test, ax=ax)

# visualizing the confidence interval
ax.fill_between(
    x=forecast_test[&#39;ds&#39;],
    y1=forecast_test[&#39;exp_yhat_lower&#39;],
    y2=forecast_test[&#39;exp_yhat_upper&#39;],
    color=&#39;green&#39;, 
    alpha=0.1,
    label=&#39;95% CI&#39;
)

plt.ylim(-5000,80000)

ax.axvline(threshold_date, color=&#39;grey&#39;, linestyle=&#39;--&#39;)
ax.legend(loc=&#39;upper left&#39;)
ax.set(title=&#39;Weekly Sales&#39;, ylabel=&#39;&#39;);</code></pre>
<div class="figure">
<img src="nb0008_sales_forecast_part_2_files/nb0008_sales_forecast_part_2_15_0.png" alt="png" />
<p class="caption">png</p>
</div>
<p>We can see right away that our forecast (green line) is consistently underestimating the observations (orange line), even though the observations are all within the 95% confidence interval of predictions. Combined with the component plots below (log scale), we can also see that the model includes a decreasing trend, and there is a large amount of uncertainty in the trend component as time goes on, as illustrated by the expanding confidence interval (shaded area). Holidays, on the other hand, do not seem to affect weekly sales for Department 1 in Store 1.</p>
<pre class="python"><code>model.plot_components(forecast, figsize=(13,7));</code></pre>
<div class="figure">
<img src="nb0008_sales_forecast_part_2_files/nb0008_sales_forecast_part_2_17_0.png" alt="png" />
<p class="caption">png</p>
</div>
<div id="residual-diagnosis" class="section level3">
<h3>Residual Diagnosis</h3>
<p>For many models, but not all, residuals are the differences between the predicted values and the observed values, and they are useful in checking whether the model has captured a sufficient amount of information from the data. In a good model, the residuals should be uncorrelated and have a mean that is close to 0. Correlated residuals signal that there is information left in the errors that can be further modeled, and a mean far away from 0 suggests that the predictions are biased.</p>
<pre class="python"><code>forecast_test[&#39;errors&#39;] = forecast_test[&#39;exp_yhat&#39;]-sales_s1d1_df_test[&#39;Weekly_Sales&#39;]

# Information on the SettingWithCopywarning that might occur: 
# https://www.dataquest.io/blog/settingwithcopywarning/

errors_mean = forecast_test[&#39;errors&#39;].mean()
errors_std = forecast_test[&#39;errors&#39;].std()

print(&#39;Residual mean: {:.2f}&#39;.format(errors_mean))
print(&#39;Residual standard deviation: {:.2f}&#39;.format(errors_std))</code></pre>
<pre><code>    Residual mean: -6369.44
    Residual standard deviation: 5974.84</code></pre>
<pre class="python"><code>fig, axes = plt.subplots(2,2,figsize=(15,10))

# Plot residual distribution
sns.distplot(a=forecast_test[&#39;errors&#39;], ax=axes[0,0], bins=15, rug=True)
axes[0,0].axvline(x=errors_mean, color=&#39;green&#39;, linestyle=&#39;--&#39;, label=r&#39;$\mu$&#39;)
axes[0,0].axvline(x=errors_mean + 2*errors_std, color=&#39;red&#39;, linestyle=&#39;--&#39;, label=r&#39;$\mu \pm 2\sigma$&#39;)
axes[0,0].axvline(x=errors_mean - 2*errors_std, color=&#39;red&#39;, linestyle=&#39;--&#39;)
axes[0,0].legend()
axes[0,0].set(title=&#39;Model Errors (Test Set)&#39;)

# Plot residuals against time
sns.scatterplot(x=&#39;ds&#39;, y=&#39;errors&#39;, data=forecast_test, ax=axes[0,1])
axes[0,1].axhline(y=errors_mean, color=&#39;green&#39;, linestyle=&#39;--&#39;, label=r&#39;$\mu$ &#39;)
axes[0,1].axhline(y=errors_mean + 2*errors_std, color=&#39;red&#39;, linestyle=&#39;--&#39;, label=r&#39;$\mu \pm 2\sigma$&#39;)
axes[0,1].axhline(y=errors_mean - 2*errors_std, color=&#39;red&#39;, linestyle=&#39;--&#39;)
axes[0,1].legend()
axes[0,1].set(title=&#39;Model Errors (Test Set)&#39;)

# Plot prediction against observations
sns.regplot(x=sales_s1d1_test[&#39;y&#39;], y=forecast_test[&#39;yhat&#39;], color=&#39;orange&#39;, label=&#39;test&#39;, ax=axes[1,0])
# Generate diagonal line to plot.
d_x = np.linspace(start=sales_s1d1_test[&#39;y&#39;].min()-0.1, stop=sales_s1d1_test[&#39;y&#39;].max()+0.1, num=100)
axes[1,0].plot(d_x, d_x, color=&#39;red&#39;, label=&#39;yhat=y&#39;, ls=&#39;:&#39;)
axes[1,0].legend()
axes[1,0].set(title=&#39;Test Data vs Predictions&#39;)

# Plot autocorrelation of residuals
plot_acf(x=forecast_test[&#39;errors&#39;], ax=axes[1,1])

plt.show()</code></pre>
<div class="figure">
<img src="nb0008_sales_forecast_part_2_files/nb0008_sales_forecast_part_2_21_0.png" alt="png" />
<p class="caption">png</p>
</div>
<pre class="python"><code># Calculate key error metrics
mean_abs_err = np.mean(abs(forecast_test[&#39;errors&#39;]))
mean_sqrd_err = np.mean(np.square(forecast_test[&#39;errors&#39;]))
rt_mean_sqrd_err = np.sqrt(mean_sqrd_err)
mean_abs_pct_err = np.mean(abs(forecast_test[&#39;errors&#39;]/sales_s1d1_test[&#39;y&#39;]))

display(pd.DataFrame({&#39;MAE&#39;: mean_abs_err,
                      &#39;MSE&#39;: mean_sqrd_err,
                      &#39;RMSE&#39;: rt_mean_sqrd_err,
                      &#39;MAPE&#39;: mean_abs_pct_err}, index=[&#39;Measurements&#39;]))</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
MAE
</th>
<th>
MSE
</th>
<th>
RMSE
</th>
<th>
MAPE
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
Measurements
</th>
<td>
6698.44868
</td>
<td>
7.558195e+07
</td>
<td>
8693.788244
</td>
<td>
659.131386
</td>
</tr>
</tbody>
</table>
</div>
<p>We can see that the mean of our residuals is smaller than 0, and our predictions were frequently underestimating the observed data. The distribution of the residuals is also skewed by some extremely negative forecasting errors (underestimation). At the same time, the plots above show that the variance of our residuals is <em>not</em> constant over time; it decreases from the beginning to the end of the year. Luckily, there is not much significant autocorrelation in the residuals.</p>
<p>In short, our forecast is very biased, but our model is effectively capturing most of the information and patterns. However, this is not to say that we cannot find a better model (<em>or more importantly, collect more data</em>). In our case, we employ Prophet because it is compatible with weekly data. Perhaps there are other parameters that we can fine-tune, or even other models that should be fitted to our data, before we make the final decision on which model to use. Again, for the sake of simplicity, we will go ahead and forecast future sales with this current model.</p>
</div>
</div>
<div id="forecasting" class="section level2">
<h2>Forecasting</h2>
<hr />
<p>Now that we have an understanding of the prediction errors in our model, we can move on to build a full model using all the existing data. However, please be careful not to test the model with the data that are used to create the model itself.</p>
<pre class="python"><code>sales_s1d1 = (sales_s1d1_df[[&#39;Date&#39;, &#39;Log_Weekly_Sales&#39;]]
              .rename(columns={&#39;Date&#39;:&#39;ds&#39;, &#39;Log_Weekly_Sales&#39;: &#39;y&#39;}))

display(sales_s1d1.tail())</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
ds
</th>
<th>
y
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
138
</th>
<td>
2012-09-28
</td>
<td>
9.849444
</td>
</tr>
<tr>
<th>
139
</th>
<td>
2012-10-05
</td>
<td>
9.994446
</td>
</tr>
<tr>
<th>
140
</th>
<td>
2012-10-12
</td>
<td>
10.032936
</td>
</tr>
<tr>
<th>
141
</th>
<td>
2012-10-19
</td>
<td>
10.093499
</td>
</tr>
<tr>
<th>
142
</th>
<td>
2012-10-26
</td>
<td>
10.217963
</td>
</tr>
</tbody>
</table>
</div>
<pre class="python"><code>model = Prophet(yearly_seasonality=True, 
                weekly_seasonality=False, 
                daily_seasonality=False, 
                holidays=holidays_s1d1, 
                interval_width=0.95, 
                mcmc_samples=100)

model.fit(sales_s1d1)

# Extend dates and features. 
future = model.make_future_dataframe(periods=sales_s1d1_test.shape[0], freq=&#39;7D&#39;)
# Generate predictions. 
forecast = model.predict(df=future)

# Back-transform the predictions and confidence intervals
forecast.loc[:,&#39;exp_yhat&#39;] = np.exp(forecast.loc[:,&#39;yhat&#39;])
forecast.loc[:,&#39;exp_yhat_upper&#39;] = np.exp(forecast.loc[:,&#39;yhat_upper&#39;])
forecast.loc[:,&#39;exp_yhat_lower&#39;] = np.exp(forecast.loc[:,&#39;yhat_lower&#39;])

display(forecast.tail())
# Scroll to the right for back-transformed forecasts</code></pre>
<pre><code>    WARNING:pystan:n_eff / iter below 0.001 indicates that the effective sample size has likely been overestimated
    WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed
    WARNING:pystan:8 of 200 iterations saturated the maximum tree depth of 10 (4 %)
    WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
ds
</th>
<th>
trend
</th>
<th>
yhat_lower
</th>
<th>
yhat_upper
</th>
<th>
trend_lower
</th>
<th>
trend_upper
</th>
<th>
additive_terms
</th>
<th>
additive_terms_lower
</th>
<th>
additive_terms_upper
</th>
<th>
holiday
</th>
<th>
…
</th>
<th>
yearly
</th>
<th>
yearly_lower
</th>
<th>
yearly_upper
</th>
<th>
multiplicative_terms
</th>
<th>
multiplicative_terms_lower
</th>
<th>
multiplicative_terms_upper
</th>
<th>
yhat
</th>
<th>
exp_yhat
</th>
<th>
exp_yhat_upper
</th>
<th>
exp_yhat_lower
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
190
</th>
<td>
2013-09-27
</td>
<td>
9.949436
</td>
<td>
8.878983
</td>
<td>
10.863036
</td>
<td>
9.005251
</td>
<td>
10.931574
</td>
<td>
-0.069406
</td>
<td>
-0.220070
</td>
<td>
0.083404
</td>
<td>
0.0
</td>
<td>
…
</td>
<td>
-0.069406
</td>
<td>
-0.220070
</td>
<td>
0.083404
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
9.880030
</td>
<td>
19536.299549
</td>
<td>
52210.357567
</td>
<td>
7179.482755
</td>
</tr>
<tr>
<th>
191
</th>
<td>
2013-10-04
</td>
<td>
9.949049
</td>
<td>
8.864927
</td>
<td>
10.906662
</td>
<td>
8.981442
</td>
<td>
10.937505
</td>
<td>
-0.066797
</td>
<td>
-0.223274
</td>
<td>
0.063376
</td>
<td>
0.0
</td>
<td>
…
</td>
<td>
-0.066797
</td>
<td>
-0.223274
</td>
<td>
0.063376
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
9.882252
</td>
<td>
19579.767680
</td>
<td>
54538.503668
</td>
<td>
7079.277725
</td>
</tr>
<tr>
<th>
192
</th>
<td>
2013-10-11
</td>
<td>
9.948662
</td>
<td>
8.951491
</td>
<td>
11.034013
</td>
<td>
8.958226
</td>
<td>
10.964481
</td>
<td>
0.002060
</td>
<td>
-0.148902
</td>
<td>
0.136651
</td>
<td>
0.0
</td>
<td>
…
</td>
<td>
0.002060
</td>
<td>
-0.148902
</td>
<td>
0.136651
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
9.950722
</td>
<td>
20967.349025
</td>
<td>
61945.667035
</td>
<td>
7719.392897
</td>
</tr>
<tr>
<th>
193
</th>
<td>
2013-10-18
</td>
<td>
9.948275
</td>
<td>
9.034649
</td>
<td>
11.254050
</td>
<td>
8.927615
</td>
<td>
10.999212
</td>
<td>
0.180019
</td>
<td>
0.032323
</td>
<td>
0.300479
</td>
<td>
0.0
</td>
<td>
…
</td>
<td>
0.180019
</td>
<td>
0.032323
</td>
<td>
0.300479
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
10.128293
</td>
<td>
25041.585266
</td>
<td>
77191.909834
</td>
<td>
8388.771142
</td>
</tr>
<tr>
<th>
194
</th>
<td>
2013-10-25
</td>
<td>
9.947888
</td>
<td>
9.218415
</td>
<td>
11.475638
</td>
<td>
8.902477
</td>
<td>
11.033823
</td>
<td>
0.376329
</td>
<td>
0.228094
</td>
<td>
0.506146
</td>
<td>
0.0
</td>
<td>
…
</td>
<td>
0.376329
</td>
<td>
0.228094
</td>
<td>
0.506146
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
0.0
</td>
<td>
10.324217
</td>
<td>
30461.435565
</td>
<td>
96339.867815
</td>
<td>
10081.072583
</td>
</tr>
</tbody>
</table>
<p>
5 rows × 25 columns
</p>
</div>
<pre class="python"><code>fig, ax = plt.subplots()
plt.rc(&#39;figure&#39;,figsize=(15,7))

sns.scatterplot(x=&#39;Date&#39;, y=&#39;Weekly_Sales&#39;, label=&#39;observations&#39;, color=&#39;orange&#39;, data=sales_s1d1_df, ax=ax)
sns.lineplot(x=&#39;ds&#39;, y=&#39;exp_yhat&#39;, label=&#39;predictions&#39;, color=&#39;green&#39;, data=forecast, ax=ax)

# visualizing the confidence interval
ax.fill_between(
    x=forecast[&#39;ds&#39;],
    y1=forecast[&#39;exp_yhat_lower&#39;],
    y2=forecast[&#39;exp_yhat_upper&#39;],
    color=&#39;green&#39;, 
    alpha=0.1,
    label=&#39;95% CI&#39;
)

# plt.ylim(-5000,80000)

ax.axvline(max(sales_s1d1_df[&#39;Date&#39;]), color=&#39;grey&#39;, linestyle=&#39;--&#39;)
ax.legend(loc=&#39;upper left&#39;)
ax.set(title=&#39;Weekly Sales&#39;, ylabel=&#39;&#39;);</code></pre>
<div class="figure">
<img src="nb0008_sales_forecast_part_2_files/nb0008_sales_forecast_part_2_27_0.png" alt="png" />
<p class="caption">png</p>
</div>
</div>
<div id="next-steps" class="section level2">
<h2>Next Steps</h2>
<hr />
<p>Now that you have a basic understanding of our data, as well as forecasting for a single time series in Python using <code>Prophet</code>, we encourage you to:</p>
<ol style="list-style-type: decimal">
<li>Read through the <a href="https://facebook.github.io/prophet/docs/quick_start.html">documentation for Prophet</a> and fine-tune any additional parameters that you think could improve our model.</li>
<li>Create your own Prophet model with a different dataset. Try to find a time series that is much longer than what we used in this Notebook so that you have more data to work with.</li>
<li>Come up with a strategy to efficiently forecast for multiple stores and departments.</li>
</ol>
</div>

<div class="footer">
  <p style="text-align: center;">
    <!-- Add icon library -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <a href="https://github.com/Master-of-Business-Analytics" class="fa fa-github fa-2x"></a>
    <br/>
    Created and maintained by the
    <br/>
    <a href="https://www.sauder.ubc.ca/programs/masters-degrees/mban">Master of Business Analytics</a> Community
    <br/>
    Licensed under a
    <br/>
    <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
    <br/>
    <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a>
  </p>
</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
